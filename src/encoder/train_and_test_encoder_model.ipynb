{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from custom_image_dataset import CustomImageDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We use: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset csv files as pd dataframes and print statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_chest_imagenome_customized = \"/u/home/tanida/datasets/chest-imagenome-dataset-customized-full\"\n",
    "\n",
    "# reduce memory usage by only using necessary columns and selecting appropriate datatypes\n",
    "usecols = [\"mimic_image_file_path\", \"bbox_name\", \"x1\", \"y1\", \"x2\", \"y2\", \"is_abnormal\"]\n",
    "dtype = {\"x1\": \"int16\", \"x2\": \"int16\", \"y1\": \"int16\", \"y2\": \"int16\", \"bbox_name\": \"category\"} \n",
    "\n",
    "datasets_as_dfs = {dataset: os.path.join(path_chest_imagenome_customized, dataset) + \".csv\" for dataset in [\"train\", \"valid\", \"test\"]}\n",
    "datasets_as_dfs = {dataset: pd.read_csv(csv_file_path, usecols=usecols, dtype=dtype) for dataset, csv_file_path in datasets_as_dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_samples_per_class(dataset, df):\n",
    "    print(f\"{dataset}:\")\n",
    "    for bbox_name, count in df[\"bbox_name\"].value_counts().iteritems():\n",
    "        print(f\"\\t{bbox_name}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of samples per class for each dataset\n",
    "\n",
    "# bboxes of anatomical regions are almost distributed equally in all datasets,\n",
    "# only a slight imbalance because not every image has bboxes of all 36 anatomical regions\n",
    "for dataset, df in datasets_as_dfs.items():\n",
    "    print_num_samples_per_class(dataset, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 5,498,017 images (69.99%)\n",
      "valid: 793,651 images (10.10%)\n",
      "test: 1,564,227 images (19.91%)\n"
     ]
    }
   ],
   "source": [
    "# get number of samples for each dataset\n",
    "total_num_samples = sum(len(df) for df in datasets_as_dfs.values())\n",
    "\n",
    "for dataset, df in datasets_as_dfs.items():\n",
    "    print(f\"{dataset}: {len(df):,} images ({(len(df) / total_num_samples) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (new): 1,649,405 samples\n"
     ]
    }
   ],
   "source": [
    "# if we don't want to train on the full train set (with 5,950,238 samples), we can specify the constant below to limit the train set\n",
    "\n",
    "PERCENTAGE_OF_TRAIN_SET_TO_USE = 0.3\n",
    "total_num_samples_train = len(datasets_as_dfs[\"train\"])\n",
    "\n",
    "new_num_samples_train = int(PERCENTAGE_OF_TRAIN_SET_TO_USE * total_num_samples_train)\n",
    "\n",
    "datasets_as_dfs[\"train\"] = datasets_as_dfs[\"train\"][:new_num_samples_train]\n",
    "\n",
    "print(f\"train (new): {len(datasets_as_dfs['train']):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets as Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants for image transformations\n",
    "\n",
    "# see compute_mean_std_dataset.py in src/dataset\n",
    "mean = 0.471\n",
    "std = 0.302\n",
    "\n",
    "# pre-trained DenseNet121 model expects images to be of size 224x224\n",
    "IMAGE_INPUT_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: transforms are applied to the already cropped images (see __getitem__ method of CustomImageDataset class)!\n",
    "\n",
    "# use albumentations for Compose and transforms\n",
    "train_transforms = A.Compose([\n",
    "    # we want the long edge of the image to be resized to IMAGE_INPUT_SIZE, and the short edge of the image to be padded to IMAGE_INPUT_SIZE on both sides,\n",
    "    # such that the aspect ratio of the images are kept (i.e. a resized image of a lung is not distorted), \n",
    "    # while getting images of uniform size (IMAGE_INPUT_SIZE x IMAGE_INPUT_SIZE)\n",
    "    A.LongestMaxSize(max_size=IMAGE_INPUT_SIZE, interpolation=cv2.INTER_AREA),  # resizes the longer edge to IMAGE_INPUT_SIZE while maintaining the aspect ratio (INTER_AREA works best for shrinking images)\n",
    "    A.PadIfNeeded(min_height=IMAGE_INPUT_SIZE, min_width=IMAGE_INPUT_SIZE, border_mode=cv2.BORDER_CONSTANT),  # pads both sides of the shorter edge with 0's (black pixels)\n",
    "    # A.HueSaturationValue(),\n",
    "    # A.Affine(mode=cv2.BORDER_CONSTANT),\n",
    "    # A.GaussianBlur(),\n",
    "    A.Normalize(mean=mean, std=std),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# don't apply data augmentations to val and test set\n",
    "val_test_transforms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=IMAGE_INPUT_SIZE, interpolation=cv2.INTER_AREA),\n",
    "    A.PadIfNeeded(min_height=IMAGE_INPUT_SIZE, min_width=IMAGE_INPUT_SIZE, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.Normalize(mean=mean, std=std),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(dataset_df=datasets_as_dfs[\"train\"], transforms=train_transforms)\n",
    "val_dataset = CustomImageDataset(dataset_df=datasets_as_dfs[\"valid\"], transforms=val_test_transforms)\n",
    "test_dataset = CustomImageDataset(dataset_df=datasets_as_dfs[\"test\"], transforms=val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000036vscode-remote?line=0'>1</a>\u001b[0m train_dataset[\u001b[39m375\u001b[39;49m]\n",
      "File \u001b[0;32m~/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py:34\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=29'>30</a>\u001b[0m cropped_image \u001b[39m=\u001b[39m image[y1:y2, x1:x2]  \u001b[39m# cropped_image = image[Y:Y+H, X:X+W]\u001b[39;00m\n\u001b[1;32m     <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=31'>32</a>\u001b[0m \u001b[39m# apply transformations\u001b[39;00m\n\u001b[1;32m     <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=32'>33</a>\u001b[0m \u001b[39m# albumentations transforms return a dict, which is why key \"image\" has to be selected\u001b[39;00m\n\u001b[0;32m---> <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=33'>34</a>\u001b[0m cropped_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(image\u001b[39m=\u001b[39;49mcropped_image)[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=35'>36</a>\u001b[0m \u001b[39m# get the bbox_name (2nd column of df) and convert it into corresponding class index\u001b[39;00m\n\u001b[1;32m     <a href='file:///u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py?line=36'>37</a>\u001b[0m bbox_class_index \u001b[39m=\u001b[39m ANATOMICAL_REGIONS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_df\u001b[39m.\u001b[39miloc[index, \u001b[39m1\u001b[39m]]\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py:210\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py?line=206'>207</a>\u001b[0m     p\u001b[39m.\u001b[39mpreprocess(data)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py?line=208'>209</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transforms):\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py?line=209'>210</a>\u001b[0m     data \u001b[39m=\u001b[39m t(force_apply\u001b[39m=\u001b[39;49mforce_apply, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py?line=211'>212</a>\u001b[0m     \u001b[39mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py?line=212'>213</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:97\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=91'>92</a>\u001b[0m             warn(\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=92'>93</a>\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_class_fullname() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=93'>94</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m because its\u001b[39m\u001b[39m'\u001b[39m\u001b[39m params depend on targets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=94'>95</a>\u001b[0m             )\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=95'>96</a>\u001b[0m         kwargs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_key][\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)] \u001b[39m=\u001b[39m deepcopy(params)\n\u001b[0;32m---> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=96'>97</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_with_params(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=98'>99</a>\u001b[0m \u001b[39mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:112\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, force_apply, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=109'>110</a>\u001b[0m     target_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=110'>111</a>\u001b[0m     target_dependencies \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dependence\u001b[39m.\u001b[39mget(key, [])}\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=111'>112</a>\u001b[0m     res[key] \u001b[39m=\u001b[39m target_function(arg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtarget_dependencies))\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=112'>113</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py?line=113'>114</a>\u001b[0m     res[key] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py:83\u001b[0m, in \u001b[0;36mLongestMaxSize.apply\u001b[0;34m(self, img, max_size, interpolation, **params)\u001b[0m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py?line=79'>80</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py?line=80'>81</a>\u001b[0m     \u001b[39mself\u001b[39m, img: np\u001b[39m.\u001b[39mndarray, max_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m, interpolation: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mINTER_LINEAR, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py?line=81'>82</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py?line=82'>83</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlongest_max_size(img, max_size\u001b[39m=\u001b[39;49mmax_size, interpolation\u001b[39m=\u001b[39;49minterpolation)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py:70\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=66'>67</a>\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=67'>68</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_function\u001b[39m(img, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=68'>69</a>\u001b[0m     shape \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=69'>70</a>\u001b[0m     result \u001b[39m=\u001b[39m func(img, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=70'>71</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=71'>72</a>\u001b[0m         result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(result, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:324\u001b[0m, in \u001b[0;36mlongest_max_size\u001b[0;34m(img, max_size, interpolation)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=321'>322</a>\u001b[0m \u001b[39m@preserve_channel_dim\u001b[39m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=322'>323</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlongest_max_size\u001b[39m(img, max_size, interpolation):\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _func_max_size(img, max_size, interpolation, \u001b[39mmax\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:318\u001b[0m, in \u001b[0;36m_func_max_size\u001b[0;34m(img, max_size, interpolation, func)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=315'>316</a>\u001b[0m \u001b[39mif\u001b[39;00m scale \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=316'>317</a>\u001b[0m     new_height, new_width \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(py3round(dim \u001b[39m*\u001b[39m scale) \u001b[39mfor\u001b[39;00m dim \u001b[39min\u001b[39;00m (height, width))\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=317'>318</a>\u001b[0m     img \u001b[39m=\u001b[39m resize(img, height\u001b[39m=\u001b[39;49mnew_height, width\u001b[39m=\u001b[39;49mnew_width, interpolation\u001b[39m=\u001b[39;49minterpolation)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=318'>319</a>\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py:70\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=66'>67</a>\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=67'>68</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_function\u001b[39m(img, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=68'>69</a>\u001b[0m     shape \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\n\u001b[0;32m---> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=69'>70</a>\u001b[0m     result \u001b[39m=\u001b[39m func(img, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=70'>71</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m     <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=71'>72</a>\u001b[0m         result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(result, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:277\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, height, width, interpolation)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=274'>275</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=275'>276</a>\u001b[0m resize_fn \u001b[39m=\u001b[39m _maybe_process_in_chunks(cv2\u001b[39m.\u001b[39mresize, dsize\u001b[39m=\u001b[39m(width, height), interpolation\u001b[39m=\u001b[39minterpolation)\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py?line=276'>277</a>\u001b[0m \u001b[39mreturn\u001b[39;00m resize_fn(img)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py:189\u001b[0m, in \u001b[0;36m_maybe_process_in_chunks.<locals>.__process_fn\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=186'>187</a>\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdstack(chunks)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=187'>188</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=188'>189</a>\u001b[0m     img \u001b[39m=\u001b[39m process_fn(img, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py?line=189'>190</a>\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "train_dataset[375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(727, len(train_dataset)):\n",
    "        train_dataset[i]\n",
    "except:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py\", line 34, in __getitem__\n    cropped_image = self.transforms(image=cropped_image)[\"image\"]\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py\", line 210, in __call__\n    data = t(force_apply=force_apply, **data)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 97, in __call__\n    return self.apply_with_params(params, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 112, in apply_with_params\n    res[key] = target_function(arg, **dict(params, **target_dependencies))\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py\", line 83, in apply\n    return F.longest_max_size(img, max_size=max_size, interpolation=interpolation)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 70, in wrapped_function\n    result = func(img, *args, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 324, in longest_max_size\n    return _func_max_size(img, max_size, interpolation, max)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 318, in _func_max_size\n    img = resize(img, height=new_height, width=new_width, interpolation=interpolation)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 70, in wrapped_function\n    result = func(img, *args, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 277, in resize\n    return resize_fn(img)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 189, in __process_fn\n    img = process_fn(img, **kwargs)\ncv2.error: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000014vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000014vscode-remote?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000014vscode-remote?line=7'>8</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/train_and_test_encoder_model.ipynb#ch0000014vscode-remote?line=8'>9</a>\u001b[0m end \u001b[39m=\u001b[39m time()\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1221'>1222</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1222'>1223</a>\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1223'>1224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1247'>1248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1248'>1249</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1249'>1250</a>\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=1250'>1251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py?line=452'>453</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py?line=453'>454</a>\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py?line=454'>455</a>\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py?line=455'>456</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/_utils.py?line=456'>457</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31merror\u001b[0m: Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/u/home/tanida/region-guided-chest-x-ray-report-generation/src/encoder/custom_image_dataset.py\", line 34, in __getitem__\n    cropped_image = self.transforms(image=cropped_image)[\"image\"]\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/composition.py\", line 210, in __call__\n    data = t(force_apply=force_apply, **data)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 97, in __call__\n    return self.apply_with_params(params, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/core/transforms_interface.py\", line 112, in apply_with_params\n    res[key] = target_function(arg, **dict(params, **target_dependencies))\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/resize.py\", line 83, in apply\n    return F.longest_max_size(img, max_size=max_size, interpolation=interpolation)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 70, in wrapped_function\n    result = func(img, *args, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 324, in longest_max_size\n    return _func_max_size(img, max_size, interpolation, max)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 318, in _func_max_size\n    img = resize(img, height=new_height, width=new_width, interpolation=interpolation)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 70, in wrapped_function\n    result = func(img, *args, **kwargs)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py\", line 277, in resize\n    return resize_fn(img)\n  File \"/u/home/tanida/.conda/envs/cxr_env/lib/python3.10/site-packages/albumentations/augmentations/functional.py\", line 189, in __process_fn\n    img = process_fn(img, **kwargs)\ncv2.error: OpenCV(4.5.5) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@107.334] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/u/home/tanida/datasets/mimic-cxr-jpg/files/p11/p11996157/s54968421/31c32ffd-aac9a015-868cb1e2-86f5a335-ac3d672f.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@108.570] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/u/home/tanida/datasets/mimic-cxr-jpg/files/p11/p11914297/s54901424/d0539208-cc42e490-6a63a524-cfa102bd-675a07c2.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import multiprocessing as mp\n",
    "for num_workers in range(2, mp.cpu_count(), 2):  \n",
    "    train_loader = DataLoader(train_dataset,shuffle=True,num_workers=num_workers,batch_size=64,pin_memory=True)\n",
    "    start = time()\n",
    "    for epoch in range(1, 3):\n",
    "        for data in train_loader:\n",
    "            continue\n",
    "    end = time()\n",
    "    print(f\"Finish with:{end - start} second, num_workers={num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    # we want the long edge of the image to be resized to IMAGE_INPUT_SIZE, and the short edge of the image to be padded to IMAGE_INPUT_SIZE on both sides,\n",
    "    # such that the aspect ratio of the images are kept (i.e. a resized image of a lung is not distorted), \n",
    "    # while getting images of uniform size (IMAGE_INPUT_SIZE x IMAGE_INPUT_SIZE)\n",
    "\n",
    "    # the custom class CustomResize resizes the longer edge to IMAGE_INPUT_SIZE while maintaining the aspect ratio\n",
    "    A.LongestMaxSize(max_size=224, interpolation=cv2.INTER_AREA),\n",
    "    A.PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imagesize\n",
      "  Downloading imagesize-1.3.0-py2.py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: imagesize\n",
      "Successfully installed imagesize-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3056, 2544)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"/u/home/tanida/datasets/mimic-cxr-jpg/files/p10/p10001401/s50225296/0009a9fb-eb905e90-824cad7c-16d40468-007f0038.jpg\"\n",
    "# image = Image.open(image_path)\n",
    "# image.size\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "image.shape\n",
    "\n",
    "# imagesize.get(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/u/home/tanida/datasets/mimic-cxr-jpg/files/p10/p10001401/s50225296/0009a9fb-eb905e90-824cad7c-16d40468-007f0038.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "bbox_coords = [245, 1800, 2264, 3042]\n",
    "cropped_image = image.crop(box=bbox_coords)\n",
    "\n",
    "print(type(cropped_image))\n",
    "print(cropped_image.size)\n",
    "display(cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.755"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.301 * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resized_cropped_image = train_transforms(image=np_cropped_image)[\"image\"]\n",
    "print(new_resized_cropped_image.shape)\n",
    "plt.imshow(new_resized_cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resized_cropped_image == resized_cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_cropped_image = transforms.functional.resize(cropped_image, size=223, max_size=224)\n",
    "print(resized_cropped_image)\n",
    "display(resized_cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.9662323987866\n",
      "[ True  True  True]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/u/home/tanida/datasets/mimic-cxr-jpg/files/p13/p13820640/s54192530/e9b7f879-0aa0b42d-5b1b752d-69ae71ac-3d0da7af.jpg\"\n",
    "cv2_img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "mean = cv2_img.mean()\n",
    "print(mean)\n",
    "last_mean_values = [3.5, 123.3, 234.3]\n",
    "print(abs(mean - last_mean_values) <= 1000)\n",
    "print(np.all([abs(mean - last_mean_values) <= 1000, abs(mean - last_mean_values) <= 10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to folder where model weights should be saved\n",
    "model_save_path = \"/u/home/tanida/weights/encoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af344a1d4a4009a9796a149eae461abe839e0a1e355ecc657514cba65d6053da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cxr_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
