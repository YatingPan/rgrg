{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import imagesize\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.full_model.evaluate_bbox_variations.custom_dataset_bbox_variations import CustomDatasetBboxVariations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_INPUT_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_partial_test_set = \"/u/home/tanida/datasets/dataset-with-reference-reports-partial-1000/test-1000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set_as_df():\n",
    "    def compute_bbox_widths_heights(row):\n",
    "        bbox_coordinates_single_image = row[\"bbox_coordinates\"]\n",
    "        widths_heights = []\n",
    "        for bbox_coords in bbox_coordinates_single_image:\n",
    "            x1, y1, x2, y2 = bbox_coords\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            widths_heights.append([width, height])\n",
    "\n",
    "        return widths_heights\n",
    "\n",
    "    def retrieve_image_widths_heights(row):\n",
    "        mimic_image_file_path = row[\"mimic_image_file_path\"]\n",
    "        width, height = imagesize.get(mimic_image_file_path)\n",
    "        return [width, height]\n",
    "\n",
    "    usecols = [\n",
    "        \"mimic_image_file_path\",\n",
    "        \"bbox_coordinates\",\n",
    "        \"bbox_labels\",\n",
    "        \"bbox_phrases\",\n",
    "        \"bbox_phrase_exists\",\n",
    "    ]\n",
    "\n",
    "    # all of the columns below are stored as strings in the csv_file\n",
    "    # however, as they are actually lists, we apply the literal_eval func to convert them to lists\n",
    "    converters = {\n",
    "        \"bbox_coordinates\": literal_eval,\n",
    "        \"bbox_labels\": literal_eval,\n",
    "        \"bbox_phrases\": literal_eval,\n",
    "        \"bbox_phrase_exists\": literal_eval,\n",
    "    }\n",
    "\n",
    "    test_set_as_df = pd.read_csv(path_to_partial_test_set, usecols=usecols, converters=converters)\n",
    "\n",
    "    # add new columns that contain the bbox_widths_heights (List[List[int]] with len(outer_list)=29 and len(inner_list) = 2)\n",
    "    # and image_width_height (List[int] of len 2)\n",
    "    test_set_as_df[\"bbox_widths_heights\"] = test_set_as_df.apply(lambda row: compute_bbox_widths_heights(row), axis=1)\n",
    "    test_set_as_df[\"image_width_height\"] = test_set_as_df.apply(lambda row: retrieve_image_widths_heights(row), axis=1)\n",
    "\n",
    "    return test_set_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_as_df = get_test_set_as_df()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mimic_image_file_path</th>\n",
       "      <th>bbox_coordinates</th>\n",
       "      <th>bbox_labels</th>\n",
       "      <th>bbox_phrases</th>\n",
       "      <th>bbox_phrase_exists</th>\n",
       "      <th>bbox_widths_heights</th>\n",
       "      <th>image_width_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[327, 231, 1200, 2114], [477, 300, 1200, 968]...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[There is no focal consolidation, pleural effu...</td>\n",
       "      <td>[True, False, False, True, False, False, True,...</td>\n",
       "      <td>[[873, 1883], [723, 668], [751, 423], [819, 72...</td>\n",
       "      <td>[2544, 3056]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[300, 382, 1227, 2332], [477, 436, 1227, 1118...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Pulmonary vasculature is normal. Lungs are cl...</td>\n",
       "      <td>[True, False, False, False, True, False, True,...</td>\n",
       "      <td>[[927, 1950], [750, 682], [778, 437], [859, 77...</td>\n",
       "      <td>[2544, 3056]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[229, 652, 1171, 2330], [386, 676, 1086, 1135...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[No acute intrathoracic process. There is no f...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[[942, 1678], [700, 459], [870, 434], [942, 76...</td>\n",
       "      <td>[2539, 2705]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mimic_image_file_path  \\\n",
       "0  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "1  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "2  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "\n",
       "                                    bbox_coordinates  \\\n",
       "0  [[327, 231, 1200, 2114], [477, 300, 1200, 968]...   \n",
       "1  [[300, 382, 1227, 2332], [477, 436, 1227, 1118...   \n",
       "2  [[229, 652, 1171, 2330], [386, 676, 1086, 1135...   \n",
       "\n",
       "                                         bbox_labels  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                        bbox_phrases  \\\n",
       "0  [There is no focal consolidation, pleural effu...   \n",
       "1  [Pulmonary vasculature is normal. Lungs are cl...   \n",
       "2  [No acute intrathoracic process. There is no f...   \n",
       "\n",
       "                                  bbox_phrase_exists  \\\n",
       "0  [True, False, False, True, False, False, True,...   \n",
       "1  [True, False, False, False, True, False, True,...   \n",
       "2  [True, False, False, False, False, True, True,...   \n",
       "\n",
       "                                 bbox_widths_heights image_width_height  \n",
       "0  [[873, 1883], [723, 668], [751, 423], [819, 72...       [2544, 3056]  \n",
       "1  [[927, 1950], [750, 682], [778, 437], [859, 77...       [2544, 3056]  \n",
       "2  [[942, 1678], [700, 459], [870, 434], [942, 76...       [2539, 2705]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_as_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vary_bbox_coords_position(row):\n",
    "    def check_coordinate(coord, dimension):\n",
    "        \"\"\"Make sure that new coordinate is still within the image.\"\"\"\n",
    "        if coord < 0:\n",
    "            return 0\n",
    "        elif coord > dimension:\n",
    "            return dimension\n",
    "        else:\n",
    "            return coord\n",
    "\n",
    "    bbox_coords_single_image = row[\"bbox_coordinates\"]  # List[List[int]] of shape 29 x 4\n",
    "    bbox_widths_heights_single_image = row[\"bbox_widths_heights\"]  # List[List[int]] of shape 29 x 2\n",
    "    relative_position_variation_bboxes = row[\"relative_position_variations\"]  # List[List[float]] of shape 29 x 2\n",
    "    image_width, image_height = row[\"image_width_height\"]  # two integers\n",
    "\n",
    "    # to store the new bbox coordinates after they have been varied\n",
    "    varied_bbox_coords_single_image = []\n",
    "\n",
    "    for bbox_coords, bbox_width_height, relative_position_variations in zip(bbox_coords_single_image, bbox_widths_heights_single_image, relative_position_variation_bboxes):\n",
    "        x1, y1, x2, y2 = bbox_coords\n",
    "        bbox_width, bbox_height = bbox_width_height\n",
    "        x_rel, y_rel = relative_position_variations\n",
    "\n",
    "        # if e.g. x_rel = 0.5 and bbox_width = 100, then x_var = 50\n",
    "        x_var = int(bbox_width * x_rel)\n",
    "        y_var = int(bbox_height * y_rel)\n",
    "\n",
    "        x1 += x_var\n",
    "        x2 += x_var\n",
    "        y1 += y_var\n",
    "        y2 += y_var\n",
    "\n",
    "        x1 = check_coordinate(x1, image_width)\n",
    "        x2 = check_coordinate(x2, image_width)\n",
    "        y1 = check_coordinate(y1, image_height)\n",
    "        y2 = check_coordinate(y2, image_height)\n",
    "\n",
    "        varied_bbox_coords_single_image.append([x1, y1, x2, y2])\n",
    "\n",
    "    return varied_bbox_coords_single_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(dataset_as_df)\n",
    "mean = 0\n",
    "std = 0.1\n",
    "\n",
    "relative_position_variations = np.random.normal(mean, std, size=(num_images, 29, 2))\n",
    "dataset_as_df[\"relative_position_variations\"] = relative_position_variations.tolist()\n",
    "dataset_as_df[\"bbox_coordinates_varied\"] = dataset_as_df.apply(lambda row: vary_bbox_coords_position(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mimic_image_file_path</th>\n",
       "      <th>bbox_coordinates</th>\n",
       "      <th>bbox_labels</th>\n",
       "      <th>bbox_phrases</th>\n",
       "      <th>bbox_phrase_exists</th>\n",
       "      <th>bbox_widths_heights</th>\n",
       "      <th>image_width_height</th>\n",
       "      <th>relative_position_variations</th>\n",
       "      <th>bbox_coordinates_varied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[327, 231, 1200, 2114], [477, 300, 1200, 968]...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[There is no focal consolidation, pleural effu...</td>\n",
       "      <td>[True, False, False, True, False, False, True,...</td>\n",
       "      <td>[[873, 1883], [723, 668], [751, 423], [819, 72...</td>\n",
       "      <td>[2544, 3056]</td>\n",
       "      <td>[[0.0002484327798317826, -0.030613123338941364...</td>\n",
       "      <td>[[327, 174, 1200, 2057], [459, 207, 1182, 875]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[300, 382, 1227, 2332], [477, 436, 1227, 1118...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[Pulmonary vasculature is normal. Lungs are cl...</td>\n",
       "      <td>[True, False, False, False, True, False, True,...</td>\n",
       "      <td>[[927, 1950], [750, 682], [778, 437], [859, 77...</td>\n",
       "      <td>[2544, 3056]</td>\n",
       "      <td>[[-0.1288327000191102, -0.04847466952915247], ...</td>\n",
       "      <td>[[181, 288, 1108, 2238], [593, 428, 1343, 1110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/u/home/tanida/datasets/mimic-cxr-jpg/files/p1...</td>\n",
       "      <td>[[229, 652, 1171, 2330], [386, 676, 1086, 1135...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[No acute intrathoracic process. There is no f...</td>\n",
       "      <td>[True, False, False, False, False, True, True,...</td>\n",
       "      <td>[[942, 1678], [700, 459], [870, 434], [942, 76...</td>\n",
       "      <td>[2539, 2705]</td>\n",
       "      <td>[[0.24228792944585484, 0.05820166856769004], [...</td>\n",
       "      <td>[[457, 749, 1399, 2427], [521, 698, 1221, 1157...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mimic_image_file_path  \\\n",
       "0  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "1  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "2  /u/home/tanida/datasets/mimic-cxr-jpg/files/p1...   \n",
       "\n",
       "                                    bbox_coordinates  \\\n",
       "0  [[327, 231, 1200, 2114], [477, 300, 1200, 968]...   \n",
       "1  [[300, 382, 1227, 2332], [477, 436, 1227, 1118...   \n",
       "2  [[229, 652, 1171, 2330], [386, 676, 1086, 1135...   \n",
       "\n",
       "                                         bbox_labels  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "\n",
       "                                        bbox_phrases  \\\n",
       "0  [There is no focal consolidation, pleural effu...   \n",
       "1  [Pulmonary vasculature is normal. Lungs are cl...   \n",
       "2  [No acute intrathoracic process. There is no f...   \n",
       "\n",
       "                                  bbox_phrase_exists  \\\n",
       "0  [True, False, False, True, False, False, True,...   \n",
       "1  [True, False, False, False, True, False, True,...   \n",
       "2  [True, False, False, False, False, True, True,...   \n",
       "\n",
       "                                 bbox_widths_heights image_width_height  \\\n",
       "0  [[873, 1883], [723, 668], [751, 423], [819, 72...       [2544, 3056]   \n",
       "1  [[927, 1950], [750, 682], [778, 437], [859, 77...       [2544, 3056]   \n",
       "2  [[942, 1678], [700, 459], [870, 434], [942, 76...       [2539, 2705]   \n",
       "\n",
       "                        relative_position_variations  \\\n",
       "0  [[0.0002484327798317826, -0.030613123338941364...   \n",
       "1  [[-0.1288327000191102, -0.04847466952915247], ...   \n",
       "2  [[0.24228792944585484, 0.05820166856769004], [...   \n",
       "\n",
       "                             bbox_coordinates_varied  \n",
       "0  [[327, 174, 1200, 2057], [459, 207, 1182, 875]...  \n",
       "1  [[181, 288, 1108, 2238], [593, 428, 1343, 1110...  \n",
       "2  [[457, 749, 1399, 2427], [521, 698, 1221, 1157...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_as_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    # see compute_mean_std_dataset.py in src/dataset\n",
    "    mean = 0.471\n",
    "    std = 0.302\n",
    "\n",
    "    # don't apply data augmentations to test set\n",
    "    test_transforms = A.Compose(\n",
    "        [\n",
    "            A.LongestMaxSize(max_size=IMAGE_INPUT_SIZE, interpolation=cv2.INTER_AREA),\n",
    "            A.PadIfNeeded(min_height=IMAGE_INPUT_SIZE, min_width=IMAGE_INPUT_SIZE, border_mode=cv2.BORDER_CONSTANT),\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),\n",
    "    )\n",
    "\n",
    "    return test_transforms\n",
    "\n",
    "test_transforms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDatasetBboxVariations(dataset_as_df, test_transforms, log=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bboxes', 'bbox_phrases', 'bbox_phrase_exists'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 315, 146])\n",
      "torch.Size([1, 112, 121])\n",
      "torch.Size([1, 71, 126])\n",
      "torch.Size([1, 121, 137])\n",
      "torch.Size([1, 100, 66])\n",
      "torch.Size([1, 73, 109])\n",
      "torch.Size([1, 45, 46])\n",
      "torch.Size([1, 50, 163])\n",
      "torch.Size([1, 331, 139])\n",
      "torch.Size([1, 111, 126])\n",
      "torch.Size([1, 76, 123])\n",
      "torch.Size([1, 132, 135])\n",
      "torch.Size([1, 105, 64])\n",
      "torch.Size([1, 73, 112])\n",
      "torch.Size([1, 45, 45])\n",
      "torch.Size([1, 50, 139])\n",
      "torch.Size([1, 194, 62])\n",
      "torch.Size([1, 479, 60])\n",
      "torch.Size([1, 50, 158])\n",
      "torch.Size([1, 48, 155])\n",
      "torch.Size([1, 34, 35])\n",
      "torch.Size([1, 252, 139])\n",
      "torch.Size([1, 124, 68])\n",
      "torch.Size([1, 82, 34])\n",
      "torch.Size([1, 126, 140])\n",
      "torch.Size([1, 39, 41])\n",
      "torch.Size([1, 80, 41])\n",
      "torch.Size([1, 20, 21])\n",
      "torch.Size([1, 194, 313])\n"
     ]
    }
   ],
   "source": [
    "sample_1_new = dataset[0]\n",
    "bboxes = sample_1_new[\"bboxes\"]\n",
    "for bbox in bboxes:\n",
    "    print(bbox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.object_detector.object_detector import ObjectDetector\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = ObjectDetector(return_feature_vectors=True)\n",
    "roi = object_detector.roi_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(size=(4,1,512,512))\n",
    "features = object_detector.backbone(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, features = object_detector._transform_inputs_for_rpn_and_roi(images, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals, _ = object_detector.rpn(images, features, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  0.0000, 265.1243, 214.5091, 408.9094],\n",
       "         [269.9316, 475.7477, 512.0000, 512.0000],\n",
       "         [196.6741,   0.0000, 221.5159,  73.7689],\n",
       "         ...,\n",
       "         [284.0431,   0.0000, 333.1023,   1.1170],\n",
       "         [408.0223,   0.0000, 421.9564,  82.1881],\n",
       "         [429.7241, 321.3693, 445.9416, 349.3703]]),\n",
       " tensor([[364.0947,  97.0798, 428.8401, 512.0000],\n",
       "         [  0.0000, 396.8503,  85.6579, 512.0000],\n",
       "         [343.2073,   0.0000, 512.0000, 255.4650],\n",
       "         ...,\n",
       "         [444.6466, 112.4482, 512.0000, 163.8498],\n",
       "         [224.0168,   0.0000, 268.2040,  50.9014],\n",
       "         [195.6041,   0.0000, 247.8583,  73.5272]]),\n",
       " tensor([[434.2826, 241.6065, 485.5868, 301.9100],\n",
       "         [103.8180,  56.6616, 124.5713,  72.2622],\n",
       "         [ 78.7888,   0.0000, 110.3002,  54.6100],\n",
       "         ...,\n",
       "         [125.9488, 339.9266, 202.5423, 402.4144],\n",
       "         [345.4297,   0.0000, 512.0000,  29.8741],\n",
       "         [215.3850, 335.2614, 226.2601, 456.3967]]),\n",
       " tensor([[341.4861, 270.6695, 392.0907, 457.8305],\n",
       "         [382.7212, 309.8226, 443.0941, 448.6550],\n",
       "         [335.5341, 251.6042, 381.0388, 456.4272],\n",
       "         ...,\n",
       "         [389.0023,   0.0000, 413.9745,  32.6935],\n",
       "         [141.6986, 281.8932, 339.0796, 361.9515],\n",
       "         [197.2138,   0.0000, 277.2858,  26.2808]])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes = images.image_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1595, 4])\n",
      "torch.Size([1559, 4])\n",
      "torch.Size([1567, 4])\n",
      "torch.Size([1539, 4])\n"
     ]
    }
   ],
   "source": [
    "print(proposals[0].shape)\n",
    "print(proposals[1].shape)\n",
    "print(proposals[2].shape)\n",
    "print(proposals[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_roi_pool_feature_maps = roi.box_roi_pool(features, proposals, image_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6260, 2048, 8, 8])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_roi_pool_feature_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af344a1d4a4009a9796a149eae461abe839e0a1e355ecc657514cba65d6053da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('cxr_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
